{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CSE 351 FINAL PROJECT\n",
        "PHRIREYAANTH POOBALARAJ\n",
        "Project #1: Movie Revenue Prediction (2-3 People)\n",
        "\n",
        "Film industry is booming, the revenues are growing. There are many factors which affect the revenue of a film. In this project, you will explore what features can help to predict the revenue.\n",
        "\n",
        "Datasets:\n",
        "\n",
        "The “movie.zip” file contains the datasets to be used for this project and a file describing the various columns in the data. You must split the dataset yourself into training, testing, and cross validation data(when required). Data points provided include cast, crew, plot keywords, budget, posters, release dates,, languages, production companies, and countries.\n",
        "\n",
        "EDA (10 points):\n",
        "\n",
        "Get familiar with the dataset and decide what features and observations will be useful. Make good use of visualizations.\n",
        "\n",
        "Specific tasks may include but are not limited to:\n",
        "\n",
        "● Clean the dataset, remove the outliers, before any data analysis. Explain what you did.\n",
        "\n",
        "● Some of the columns contain lists and dictionaries. Extract information you need and reformat them.\n",
        "\n",
        "● Count the number of movies released by day of week, month and year, are there any patterns that you observe?\n",
        "\n",
        "● What are the movie genre trend shifting patterns that you can observe from the dataset?\n",
        "\n",
        "● What are the strongest and weakest features correlated with movie revenue?\n",
        "\n",
        "● You can also use some external datasets to integrate into your revenue prediction analysis to make it better.\n",
        "\n",
        "Modeling and Question Answering (10 points):\n",
        "\n",
        "Extract the features you think are necessary in predicting the movie revenue.\n",
        "\n",
        "Build three models, train them on the training set, and predict the revenue on the test set (after dropping the revenue column in the test set). Explain how each model works (briefly introduce the machine learning algorithms behind them). Evaluate the performance of each model based on the original outcome in the test set. If your predictions are not so accurate, what do you think is the reason? Report your accuracy using metrics such as Residual Standard Error (RSE). Split the data further to include a cross validation set. Did this improve your model’s performance on the test set?\n",
        "\n",
        "Project Report (10 points):\n",
        "\n",
        "You are required to document your project, which can be included in the notebook itself. Don't forget to include the team members contribution information in the documentation. Include visualizations to prove your point. You should prepare a powerpoint presentation, which can help you during the demo.\n",
        "\n",
        "Demo (5 points):\n",
        "\n",
        "Sign up for a Zoom session with the mentor to present your project. All the team members should be present during the demo. Be prepared to answer questions related to your work. You should present your findings for the project, and you should also be able to run your code.\n",
        "\n",
        "Submission:\n",
        "\n",
        "Submit the following on Blackboard:\n",
        "\n",
        "Code in pdf and ipynb format\n",
        "Project Presentation in Powerpoint format"
      ],
      "metadata": {
        "id": "taBwYD6QIlyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Upload"
      ],
      "metadata": {
        "id": "ZU-KNtmtGyxp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Fgi2Zq7C-CEJ",
        "outputId": "31b701c3-3209-49ea-e74c-feafa37922a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3ae3bbf4-35ad-474b-b33f-a186d817c83e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3ae3bbf4-35ad-474b-b33f-a186d817c83e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tmdb_5000_credits.csv to tmdb_5000_credits (1).csv\n",
            "Saving tmdb_5000_movies.csv to tmdb_5000_movies (1).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell uses the `google.colab` module to manually upload local files into the Colab environment.\n"
      ],
      "metadata": {
        "id": "8-cyzM_-M8ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the movies dataset\n",
        "movies_df = pd.read_csv('tmdb_5000_movies (1).csv')\n",
        "\n",
        "# Load the credits dataset\n",
        "credits_df = pd.read_csv('tmdb_5000_credits (1).csv')\n",
        "\n",
        "# Preview the datasets\n",
        "print(\"Movies DataFrame:\")\n",
        "print(movies_df.head())\n",
        "\n",
        "print(\"\\nCredits DataFrame:\")\n",
        "print(credits_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yNMiY5UL_O0z",
        "outputId": "5bd765d4-8b82-4a96-95f3-80382799b82f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movies DataFrame:\n",
            "      budget                                             genres  \\\n",
            "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
            "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
            "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
            "3  250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
            "4  260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
            "\n",
            "                                       homepage      id  \\\n",
            "0                   http://www.avatarmovie.com/   19995   \n",
            "1  http://disney.go.com/disneypictures/pirates/     285   \n",
            "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
            "3            http://www.thedarkknightrises.com/   49026   \n",
            "4          http://movies.disney.com/john-carter   49529   \n",
            "\n",
            "                                            keywords original_language  \\\n",
            "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
            "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
            "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
            "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
            "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
            "\n",
            "                             original_title  \\\n",
            "0                                    Avatar   \n",
            "1  Pirates of the Caribbean: At World's End   \n",
            "2                                   Spectre   \n",
            "3                     The Dark Knight Rises   \n",
            "4                               John Carter   \n",
            "\n",
            "                                            overview  popularity  \\\n",
            "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
            "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
            "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
            "3  Following the death of District Attorney Harve...  112.312950   \n",
            "4  John Carter is a war-weary, former military ca...   43.926995   \n",
            "\n",
            "                                production_companies  \\\n",
            "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
            "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
            "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
            "3  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
            "4        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
            "\n",
            "                                production_countries release_date     revenue  \\\n",
            "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
            "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
            "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
            "3  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16  1084939099   \n",
            "4  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   284139100   \n",
            "\n",
            "   runtime                                   spoken_languages    status  \\\n",
            "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
            "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
            "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
            "3    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
            "4    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
            "\n",
            "                                          tagline  \\\n",
            "0                     Enter the World of Pandora.   \n",
            "1  At the end of the world, the adventure begins.   \n",
            "2                           A Plan No One Escapes   \n",
            "3                                 The Legend Ends   \n",
            "4            Lost in our world, found in another.   \n",
            "\n",
            "                                      title  vote_average  vote_count  \n",
            "0                                    Avatar           7.2       11800  \n",
            "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
            "2                                   Spectre           6.3        4466  \n",
            "3                     The Dark Knight Rises           7.6        9106  \n",
            "4                               John Carter           6.1        2124  \n",
            "\n",
            "Credits DataFrame:\n",
            "   movie_id                                     title  \\\n",
            "0     19995                                    Avatar   \n",
            "1       285  Pirates of the Caribbean: At World's End   \n",
            "2    206647                                   Spectre   \n",
            "3     49026                     The Dark Knight Rises   \n",
            "4     49529                               John Carter   \n",
            "\n",
            "                                                cast  \\\n",
            "0  [{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...   \n",
            "1  [{\"cast_id\": 4, \"character\": \"Captain Jack Spa...   \n",
            "2  [{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...   \n",
            "3  [{\"cast_id\": 2, \"character\": \"Bruce Wayne / Ba...   \n",
            "4  [{\"cast_id\": 5, \"character\": \"John Carter\", \"c...   \n",
            "\n",
            "                                                crew  \n",
            "0  [{\"credit_id\": \"52fe48009251416c750aca23\", \"de...  \n",
            "1  [{\"credit_id\": \"52fe4232c3a36847f800b579\", \"de...  \n",
            "2  [{\"credit_id\": \"54805967c3a36829b5002c41\", \"de...  \n",
            "3  [{\"credit_id\": \"52fe4781c3a36847f81398c3\", \"de...  \n",
            "4  [{\"credit_id\": \"52fe479ac3a36847f813eaa3\", \"de...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Imports the `pandas` library for data manipulation.\n",
        "- Loads two CSV files into separate pandas DataFrames:\n",
        "  - `movies_df`: Contains metadata about movies (e.g., title, budget, genres, revenue).\n",
        "  - `credits_df`: Contains casting and crew information.\n",
        "- Displays the first few rows of each dataset using `head()` to verify successful loading."
      ],
      "metadata": {
        "id": "H9yVeC07NEvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "l8z5TLMnHGh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# original count\n",
        "original_movie_count = movies_df.shape[0]\n",
        "\n",
        "cleaned_movies_df = movies_df.query(\n",
        "    '(budget <= 175_000_000) and (revenue <= 700_000_000) and '\n",
        "    '(vote_count <= 8000) and (3.5 <= vote_average <= 8.3) and '\n",
        "    '(popularity <= 150) and (runtime >= 60) and (runtime <= 200)'\n",
        ").dropna(subset=['runtime']).copy()\n",
        "\n",
        "# Count removed movies\n",
        "removed_movie_count = original_movie_count - cleaned_movies_df.shape[0]\n",
        "\n",
        "# valid movie IDs\n",
        "valid_movie_ids = cleaned_movies_df['id'].unique()\n",
        "cleaned_credits_df = credits_df[credits_df['movie_id'].isin(valid_movie_ids)].copy()\n",
        "\n",
        "# Reset indices\n",
        "cleaned_movies_df.reset_index(drop=True, inplace=True)\n",
        "cleaned_credits_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Final\n",
        "print(\"Original number of movies:\", original_movie_count)\n",
        "print(\"Movies remaining after composite filter:\", len(cleaned_movies_df))\n",
        "print(\"Movies removed:\", removed_movie_count)\n",
        "print(\"Credits remaining:\", len(cleaned_credits_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FHSLDiO9_jtl",
        "outputId": "e88d3cfb-4075-4fc7-dfac-848d56ce3174"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of movies: 4803\n",
            "Movies remaining after composite filter: 4504\n",
            "Movies removed: 299\n",
            "Credits remaining: 4504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code cell is primarily focused on cleaning and refining the TMDB movies and credits datasets. It starts by noting the original count of movies and then applies filters to eliminate outliers based on various criteria such as budget (capped at $175 million), revenue (capped at $700 million), vote count (up to 8,000), average rating (between 3.5 and 8.3), popularity (up to 150), and runtime (between 60 and 200 minutes). Additionally, movies with missing runtime values are removed to ensure complete data. Once filtering is complete, it calculates the number of movies removed from the original dataset. Following this, the credits dataset is filtered to only retain entries that correspond to the remaining valid movie IDs, ensuring both datasets are in sync. Finally, both DataFrames have their indices reset for tidiness, and the script provides a summary including the number of original movies, the remaining count, removed count, and the number of credits linked to the filtered movie set. This cleaning step is vital for removing noise and extreme values, enhancing the reliability and performance of subsequent models.\n"
      ],
      "metadata": {
        "id": "mB3Agq9GNtyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Extract revenue\n",
        "revenue_array = cleaned_movies_df['revenue'].to_numpy()\n",
        "revenue_array = revenue_array[~np.isnan(revenue_array)]  # remove NaNs\n",
        "\n",
        "#  statistics\n",
        "mean_revenue = np.mean(revenue_array)\n",
        "median_revenue = np.median(revenue_array)\n",
        "std_revenue = np.std(revenue_array, ddof=1)  # sample std dev to match pandas\n",
        "\n",
        "# Print\n",
        "print(f\"Mean Revenue: ${mean_revenue:,.2f}\")\n",
        "print(f\"Median Revenue: ${median_revenue:,.2f}\")\n",
        "print(f\"Standard Deviation of Revenue: ${std_revenue:,.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BhDBvU2S_-hw",
        "outputId": "ace8719e-e4a2-4533-d2dd-6e90e3be76c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Revenue: $66,495,724.18\n",
            "Median Revenue: $19,475,081.50\n",
            "Standard Deviation of Revenue: $107,108,987.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, it converts the 'revenue' column into a NumPy array and removes any NaN values. Why? So that our calculations don't get messed up by any missing info.\n",
        "\n",
        "Then, with the help of NumPy, it figures out the mean, median, and standard deviation of the 'revenue' column. Don’t worry, it calculates the standard deviation using ddof=1, just like pandas does. Alright, in a moment, we’ll see these results printed out. Nothing fancy, just the values formatted as U.S. dollars with two decimal points.\n",
        "\n",
        "The basic reasoning behind this was to summarize our movie revenue column and make it easier to understand. This quick overview should make it easier for us to decide what to do with the data later on.\n",
        "\n"
      ],
      "metadata": {
        "id": "HwH6SdQbN-5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "xFU32__9HMa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from collections import Counter\n",
        "\n",
        "df = pd.merge(cleaned_movies_df, cleaned_credits_df, left_on='id', right_on='movie_id')\n",
        "\n",
        "# Parse genres\n",
        "def parse_column_list(x, key='name'):\n",
        "    try:\n",
        "        return [d.get(key) for d in ast.literal_eval(x) if isinstance(d, dict)]\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "df['genre_list'] = df['genres'].map(lambda x: parse_column_list(x))\n",
        "all_genres = [g for genres in df['genre_list'] for g in genres]\n",
        "genre_counts = pd.Series(all_genres).value_counts()\n",
        "common_genres = set(genre_counts[genre_counts >= 50].index)\n",
        "\n",
        "for genre in common_genres:\n",
        "    df[f'genre_{genre}'] = df['genre_list'].map(lambda genres: int(genre in genres))\n",
        "\n",
        "df['genre_Other'] = df['genre_list'].map(lambda genres: int(any(g not in common_genres for g in genres)))\n",
        "\n",
        "#  Budget/Popularity\n",
        "df['log_budget'] = np.log1p(df['budget'])\n",
        "df['log_popularity'] = np.log1p(df['popularity'])\n",
        "\n",
        "# Budget\n",
        "budget_bins = [0, 2e7, 1e8, np.inf]\n",
        "budget_labels = ['low', 'mid', 'high']\n",
        "df['budget_bucket'] = pd.cut(df['budget'], bins=budget_bins, labels=budget_labels)\n",
        "df = pd.concat([df, pd.get_dummies(df['budget_bucket'], prefix='budget')], axis=1)\n",
        "\n",
        "#  Runtime\n",
        "runtime_bins = [0, 90, 130, np.inf]\n",
        "runtime_labels = ['short', 'medium', 'long']\n",
        "df['runtime_bucket'] = pd.cut(df['runtime'], bins=runtime_bins, labels=runtime_labels)\n",
        "df = pd.concat([df, pd.get_dummies(df['runtime_bucket'], prefix='runtime')], axis=1)\n",
        "\n",
        "#  Date Feats\n",
        "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
        "df['release_year'] = df['release_date'].dt.year\n",
        "\n",
        "df['release_month'] = df['release_date'].dt.month\n",
        "df['release_day_of_week'] = df['release_date'].dt.dayofweek.fillna(4).astype(int)\n",
        "\n",
        "df['is_summer_release'] = df['release_month'].isin([5,6,7,8]).astype(int)\n",
        "df['is_holiday_release'] = df['release_month'].isin([11,12]).astype(int)\n",
        "df['is_spring_break'] = df['release_month'].isin([3,4]).astype(int)\n",
        "\n",
        "df = pd.concat([df, pd.get_dummies(df['release_month'], prefix='month')], axis=1)\n",
        "\n",
        "def five_year_bin(year):\n",
        "    if pd.isna(year): return 'Unknown'\n",
        "    if year < 1980: return 'Before 1980'\n",
        "    base = int(year // 5 * 5)\n",
        "    return f'{base}-{base+4}'\n",
        "\n",
        "df['release_5yr'] = df['release_year'].map(five_year_bin)\n",
        "df = pd.concat([df, pd.get_dummies(df['release_5yr'], prefix='period')], axis=1)\n",
        "\n",
        "df['production_company_list'] = df['production_companies'].map(parse_column_list)\n",
        "\n",
        "major_studios = [\n",
        "    'Warner Bros', 'Warner Bros.', 'Universal Pictures', 'Walt Disney', 'Disney',\n",
        "    'Columbia Pictures', 'Paramount', 'Paramount Pictures', '20th Century Fox',\n",
        "    'New Line Cinema', 'Sony Pictures', 'MGM', 'Lionsgate', 'DreamWorks']\n",
        "\n",
        "for studio in major_studios:\n",
        "    col_name = f'studio_{studio.replace(\" \", \"_\").replace(\".\", \"\").lower()}'\n",
        "    df[col_name] = df['production_company_list'].map(lambda lst: int(any(studio in x for x in lst)))\n",
        "\n",
        "df['is_major_studio'] = df['production_company_list'].map(\n",
        "    lambda lst: int(any(any(studio in c for studio in major_studios) for c in lst))\n",
        ")\n",
        "\n",
        "#   average revenue\n",
        "studio_revenue = {}\n",
        "for _, row in df.iterrows():\n",
        "    for company in row['production_company_list']:\n",
        "        studio_revenue.setdefault(company, []).append(row['revenue'])\n",
        "\n",
        "studio_avg = {k: np.mean(v) for k, v in studio_revenue.items() if v}\n",
        "df['studio_avg_revenue'] = df['production_company_list'].map(\n",
        "    lambda lst: max([studio_avg.get(name, 0) for name in lst]) if lst else 0\n",
        ")\n",
        "\n",
        "#  Franchise\n",
        "def extract_collection(x):\n",
        "    try:\n",
        "        return ast.literal_eval(x)['name'] if pd.notna(x) and x != 'null' else None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "if 'belongs_to_collection' in df.columns:\n",
        "    df['is_franchise'] = df['belongs_to_collection'].map(lambda x: int(pd.notna(x) and x != 'null'))\n",
        "    df['collection_name'] = df['belongs_to_collection'].map(extract_collection)\n",
        "    collection_avg = df.groupby('collection_name')['revenue'].mean().to_dict()\n",
        "    df['franchise_avg_revenue'] = df['collection_name'].map(lambda x: collection_avg.get(x, 0) if x else 0)\n",
        "else:\n",
        "    df['is_franchise'] = 0\n",
        "    df['franchise_avg_revenue'] = 0\n",
        "\n",
        "#  Director & Cast\n",
        "def extract_director(crew):\n",
        "    try:\n",
        "        return next((m['name'] for m in ast.literal_eval(crew) if m['job'] == 'Director'), None)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "df['director'] = df['crew'].map(extract_director)\n",
        "df['vote_weighted'] = df['vote_average'] * np.log1p(df['vote_count'])\n",
        "\n",
        "high_impact = df[(df['budget'] > 5e7) & (df['vote_weighted'] > df['vote_weighted'].quantile(0.75))]\n",
        "top_directors = set(high_impact['director'].value_counts()[lambda x: x >= 5].index)\n",
        "df['is_famous_director'] = df['director'].map(lambda x: int(x in top_directors))\n",
        "\n",
        "director_avg = df.groupby('director')['revenue'].mean().to_dict()\n",
        "df['director_avg_revenue'] = df['director'].map(lambda x: director_avg.get(x, 0) if x else 0)\n",
        "\n",
        "def extract_cast_names(cast):\n",
        "    try:\n",
        "        return [d['name'] for d in ast.literal_eval(cast)]\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "df['cast_names'] = df['cast'].map(extract_cast_names)\n",
        "\n",
        "actor_counter = Counter()\n",
        "for names in high_impact['cast'].map(extract_cast_names):\n",
        "    actor_counter.update(names)\n",
        "top_actors = {name for name, count in actor_counter.items() if count >= 5}\n",
        "\n",
        "df['has_famous_actor'] = df['cast_names'].map(lambda names: int(any(n in top_actors for n in names)))\n",
        "df['famous_actor_count'] = df['cast_names'].map(lambda names: sum(n in top_actors for n in names))\n",
        "\n",
        "#  Interaction terms\n",
        "df['lang_non_en'] = (df['original_language'] != 'en').astype(int)\n",
        "df['budget_x_popularity'] = df['log_budget'] * df['popularity']\n",
        "df['budget_x_runtime'] = df['log_budget'] * df['runtime']\n",
        "df['budget_x_vote_weighted'] = df['log_budget'] * df['vote_weighted']\n",
        "df['franchise_x_budget'] = df['is_franchise'] * df['log_budget']\n",
        "df['famous_director_x_budget'] = df['is_famous_director'] * df['log_budget']\n",
        "df['famous_actor_x_budget'] = df['has_famous_actor'] * df['log_budget']\n",
        "df['holiday_family_film'] = df['is_holiday_release'] * df.get('genre_Family', 0)\n",
        "df['summer_action_film'] = df['is_summer_release'] * df.get('genre_Action', 0)\n",
        "df['franchise_famous_actor'] = df['is_franchise'] * df['famous_actor_count']\n",
        "df['franchise_famous_director'] = df['is_franchise'] * df['is_famous_director']\n",
        "df['major_studio_budget'] = df['is_major_studio'] * df['log_budget']\n",
        "df['weekend_release'] = (df['release_day_of_week'] >= 4).astype(int)\n",
        "df['weekend_summer_release'] = df['weekend_release'] * df['is_summer_release']\n",
        "\n",
        "#  Polynomial terms\n",
        "df['log_budget_squared'] = df['log_budget'] ** 2\n",
        "df['popularity_squared'] = df['popularity'] ** 2\n",
        "df['vote_weighted_squared'] = df['vote_weighted'] ** 2\n",
        "df['runtime_squared'] = df['runtime'] ** 2\n",
        "\n",
        "df['runtime'] = df['runtime'].fillna(df['runtime'].mean())\n",
        "df['budget_x_runtime'] = df['log_budget'] * df['runtime']\n",
        "df['runtime_squared'] = df['runtime'] ** 2\n",
        "\n",
        "unused_cols = [\n",
        "    'genre_list', 'cast_names', 'runtime_bucket', 'release_month', 'season',\n",
        "    'belongs_to_collection', 'crew', 'cast', 'genres', 'homepage',\n",
        "    'original_language', 'overview', 'production_companies',\n",
        "    'production_countries', 'spoken_languages', 'tagline', 'title', 'keywords',\n",
        "    'release_5yr', 'collection_name', 'production_company_list',\n",
        "    'vote_average', 'vote_count', 'has_homepage', 'num_cast',\n",
        "    'num_production_companies', 'popularity_per_year', 'budget_per_year']\n",
        "\n",
        "df.drop(columns=[col for col in unused_cols if col in df.columns], inplace=True)"
      ],
      "metadata": {
        "id": "ggKpYmwvAgrm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially, the dataset undergoes merging on id and movie_id, combining the movie metadata with the crew and cast details. Individual genre labels are derived from the genres column, and new binary columns for frequently occurring genres (50+ occurrences) are generated, along with an \"Other\" genres column.\n",
        "\n",
        "Several numerical transformations are conducted, such as log transforming the budget and popularity (results in: log_budget and log_popularity) to minimize skewness. Furthermore, budgets and runtimes are categorized into ranges (like short vs. long runtime) and are undergo one-hot encoding.\n",
        "\n",
        "The release_date column is processed to obtain information like the year, month, day of the week, and seasonal indications such as is_summer_release, is_holiday_release, and is_spring_break. Month and 5-year periods also undergo one-hot encoding.\n",
        "\n",
        "Information in the production_companies column is utilized to verify if a movie was created by a major studio, and the average revenue of those studios, which is then merged back into a column labeled studio_avg_revenue. If a movie is part of any franchise (from belongs_to_collection), that fact is logged, and average franchise revenue is calculated similarly.\n",
        "\n",
        "The crew column is examined to fetch the director's identity, marking directors who have handled 5+ high-budget & vote-weighted movies as \"famous,\" leading to the creation of is_famous_director and director_avg_revenue features. Likewise, top actors (often involved in high-impact films) are pointed out, leading to features like has_famous_actor and famous_actor_count.\n",
        "\n",
        "Interactions are appended to capture intricate variable relationships (e.g., log_budget * vote_weighted or is_summer_release * genre_Action). Polynomial features, such as squared figures for budget, popularity, runtime, and vote-weighted scores, are incorporated to handle non-linear effects.\n",
        "\n",
        "In conclusion, any missing runtime information is replaced with the column's mean, and columns that are unused or redundant (e.g., predominantly textual, ID columns, or original categorical fields) are eliminated, leaving the dataset organized and model-ready.\n",
        "\n",
        "This entire transformation turns raw movie data into an enlightening and organized feature collection suitable for regression and forecasting analytics."
      ],
      "metadata": {
        "id": "4ML230fJOPhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection/Definition"
      ],
      "metadata": {
        "id": "L_Uqlg0FHTF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Target\n",
        "y = df['revenue']\n",
        "\n",
        "# exists\n",
        "if 'is_franchise' not in df.columns:\n",
        "    df['is_franchise'] = 0\n",
        "\n",
        "# Define\n",
        "feature_groups = {\n",
        "    \"base\": [\n",
        "        'log_budget', 'popularity', 'runtime',\n",
        "        'is_famous_director', 'has_famous_actor', 'vote_weighted', 'is_franchise',\n",
        "        'director_avg_revenue', 'studio_avg_revenue', 'franchise_avg_revenue',\n",
        "        'famous_actor_count', 'is_major_studio'\n",
        "    ],\n",
        "    \"seasonality\": [\n",
        "        'release_day_of_week', 'is_summer_release',\n",
        "        'is_holiday_release', 'is_spring_break', 'weekend_release'\n",
        "    ],\n",
        "    \"month\": [col for col in df.columns if col.startswith('month_')],\n",
        "    \"studio\": [col for col in df.columns if col.startswith('studio_') and col != 'studio_avg_revenue'],\n",
        "    \"interactions\": [\n",
        "        'budget_x_popularity', 'budget_x_runtime', 'budget_x_vote_weighted',\n",
        "        'franchise_x_budget', 'famous_director_x_budget', 'famous_actor_x_budget',\n",
        "        'holiday_family_film', 'summer_action_film', 'franchise_famous_actor',\n",
        "        'franchise_famous_director', 'major_studio_budget', 'weekend_summer_release'\n",
        "    ],\n",
        "    \"polynomials\": [\n",
        "        'log_budget_squared', 'popularity_squared',\n",
        "        'vote_weighted_squared', 'runtime_squared'\n",
        "    ],\n",
        "    \"runtime\": [col for col in df.columns if col.startswith('runtime_')],\n",
        "    \"language\": ['lang_non_en'] if 'lang_non_en' in df.columns else [],\n",
        "    \"genres\": [col for col in df.columns if col.startswith('genre_')],\n",
        "    \"season_flags\": [col for col in df.columns if col.startswith('season_')],\n",
        "    \"budget_bucket\": [col for col in df.columns if col.startswith('budget_')],\n",
        "    \"period\": [col for col in df.columns if col.startswith('period_')]\n",
        "}\n",
        "\n",
        "# Flatten\n",
        "feature_cols = [feat for group in feature_groups.values() for feat in group]\n",
        "\n",
        "# Subset data\n",
        "X = df[feature_cols]\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "DOYRKc8jDypU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell then organizes features into logical categories, using a dictionary called feature_groups. These groups consist of core features, seasonal indicators, one-hot encoded months, interaction terms, polynomial terms, runtime buckets, language indicators, and others. Each group is extracted by filtering column names based on consistent prefixes like month_ or genre_. The entire set of selected features is then flattened into a single list called feature_cols.\n",
        "\n",
        "With the complete feature matrix X and the target y, the dataset is split into training and testing subsets using train_test_split, setting aside 20% of the data for testing. A fixed random seed (random_state=42) is used for reproducibility. This split is a common step before training machine learning models, ensuring performance is evaluated on unseen data.\n"
      ],
      "metadata": {
        "id": "Lg1JkDvcOgtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Target variable\n",
        "y = df['revenue']\n",
        "\n",
        "# exists\n",
        "if 'is_franchise' not in df.columns:\n",
        "    df['is_franchise'] = 0\n",
        "\n",
        "# Drop\n",
        "df = df.drop(columns=['budget_bucket', 'runtime_bucket'], errors='ignore')\n",
        "\n",
        "#  Feature\n",
        "feature_groups = {\n",
        "    \"base\": [\n",
        "        'log_budget', 'popularity', 'runtime',\n",
        "        'is_famous_director', 'has_famous_actor', 'vote_weighted', 'is_franchise',\n",
        "        'director_avg_revenue', 'studio_avg_revenue', 'franchise_avg_revenue',\n",
        "        'famous_actor_count', 'is_major_studio'\n",
        "    ],\n",
        "    \"seasonality\": [\n",
        "        'release_day_of_week', 'is_summer_release',\n",
        "        'is_holiday_release', 'is_spring_break', 'weekend_release'\n",
        "    ],\n",
        "    \"month\": [col for col in df.columns if col.startswith('month_')],\n",
        "    \"studio\": [col for col in df.columns if col.startswith('studio_') and col != 'studio_avg_revenue'],\n",
        "    \"interactions\": [\n",
        "        'budget_x_popularity', 'budget_x_runtime', 'budget_x_vote_weighted',\n",
        "        'franchise_x_budget', 'famous_director_x_budget', 'famous_actor_x_budget',\n",
        "        'holiday_family_film', 'summer_action_film', 'franchise_famous_actor',\n",
        "        'franchise_famous_director', 'major_studio_budget', 'weekend_summer_release'\n",
        "    ],\n",
        "    \"polynomials\": [\n",
        "        'log_budget_squared', 'popularity_squared',\n",
        "        'vote_weighted_squared', 'runtime_squared'\n",
        "    ],\n",
        "    \"runtime\": [col for col in df.columns if col.startswith('runtime_')],\n",
        "    \"language\": ['lang_non_en'] if 'lang_non_en' in df.columns else [],\n",
        "    \"genres\": [col for col in df.columns if col.startswith('genre_')],\n",
        "    \"season_flags\": [col for col in df.columns if col.startswith('season_')],\n",
        "    \"budget_bucket\": [col for col in df.columns if col.startswith('budget_')],\n",
        "    \"period\": [col for col in df.columns if col.startswith('period_')]\n",
        "}\n",
        "\n",
        "# Combine\n",
        "feature_cols = [feat for group in feature_groups.values() for feat in group]\n",
        "\n",
        "# Subset X matrix\n",
        "X = df[feature_cols].copy()\n",
        "\n",
        "non_numeric_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "if len(non_numeric_cols) > 0:\n",
        "    print(\"Dropping non-numeric columns:\", list(non_numeric_cols))\n",
        "    X.drop(columns=non_numeric_cols, inplace=True)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Linear Regression model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Get coefficients\n",
        "coeffs = pd.Series(lr_model.coef_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"Feature Importances (Linear Coefficients):\")\n",
        "print(coeffs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dIr9g9dIEJd4",
        "outputId": "05a12576-8ae5-4ad6-ce55-0077d715b4b9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances (Linear Coefficients):\n",
            "budget_high             9.282254e+07\n",
            "budget_mid              2.699072e+07\n",
            "budget_low              2.161976e+07\n",
            "period_1990-1994        2.069754e+07\n",
            "studio_sony_pictures    1.381626e+07\n",
            "                            ...     \n",
            "period_2015-2019       -1.277751e+07\n",
            "has_famous_actor       -1.321004e+07\n",
            "genre_Western          -1.665816e+07\n",
            "is_major_studio        -3.194385e+07\n",
            "is_famous_director     -9.457685e+07\n",
            "Length: 97, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell finalizes feature selection, handles data cleanup, and fits a linear regression model to predict movie revenue. First, it defines revenue as the target variable y and ensures the is_franchise column exists to avoid missing feature issues. Then, it drops two raw categorical columns—budget_bucket and runtime_bucket—if they exist, since those features are already encoded numerically elsewhere.\n",
        "\n",
        "Next, the code defines feature_groups, which organizes features into logical categories such as base features, seasonality indicators, interaction terms, polynomial transformations, studio identifiers, and genre encodings. Columns with specific prefixes (e.g., month_, genre_, studio_) are dynamically selected. These groups are then flattened into a single list of features called feature_cols.\n",
        "\n",
        "Using this feature list, the matrix X is created by subsetting the main DataFrame. To prevent training errors, any columns with non-numeric data types are identified and removed. A warning is printed if any such columns are dropped.\n",
        "\n",
        "Afterward, the dataset is split into training and testing sets using train_test_split, reserving 20% of the data for evaluation, with a fixed random seed for reproducibility. A linear regression model is then trained on the training data, and its learned coefficients are extracted, sorted by magnitude, and displayed. These coefficients represent the importance and direction of each feature’s impact on predicted revenue."
      ],
      "metadata": {
        "id": "79_Fd8ZlOsAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression"
      ],
      "metadata": {
        "id": "QNKVEPHhHf1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score\n",
        ")\n",
        "\n",
        "#   Training\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#   Prediction\n",
        "y_pred = model.predict(X_test)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "#   Metrics\n",
        "metrics = {\n",
        "    \"MAE\": mean_absolute_error(y_test, y_pred),\n",
        "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "    \"R²\": r2_score(y_test, y_pred),\n",
        "    \"RSE\": np.sqrt(np.sum(residuals ** 2) / (len(y_test) - 2)),\n",
        "    \"Mean Residual\": residuals.mean()\n",
        "}\n",
        "\n",
        "#  Output\n",
        "print(\"\\nLinear Regression Evaluation:\")\n",
        "for key, value in metrics.items():\n",
        "    if key == \"R²\":\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value:.2f}\")\n",
        "\n",
        "#  Bias\n",
        "direction = \"Underpredicting\" if metrics[\"Mean Residual\"] > 0 else \"Overpredicting\"\n",
        "print(f\"Mean Residual: {metrics['Mean Residual']:.2f} — {direction} on average\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wXQ_CXEtFk72",
        "outputId": "e584c2d3-31a1-4fa7-d588-de5b3d7380ff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Linear Regression Evaluation:\n",
            "MAE: 36179445.72\n",
            "RMSE: 56690486.65\n",
            "R²: 0.7686\n",
            "RSE: 56753511.11\n",
            "Mean Residual: 2139281.73\n",
            "Mean Residual: 2139281.73 — Underpredicting on average\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, the evaluation of a trained Linear Regression model on the test dataset is carried out. Initially, several packages are imported. Next, the training dataset (X_train, y_train) is employed to train an instance of a Linear Regression model. Then, predictions on the test dataset are made and they subtract the predictions from the actual revenue values to obtain the residual values (y_test - y_pred).\n",
        "\n",
        "To evaluate the Linear Regression model's accuracy, several metrics are calculated, including Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), R² or the Coefficient of Determination, Residual Standard Error (RSE), and the Mean Residual concerning residuals.\n",
        "\n",
        "These results are stored in a dictionary and printed neatly. Finally, they also focus on the Mean Residual to see if the model tends to underpredict or overpredict the target revenue on average, which would otherwise mislead the evaluation based only on absolute values. So, they refer to it as the \"Direction of the Model\" bias.\n"
      ],
      "metadata": {
        "id": "X0YKdQYhO8ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbors"
      ],
      "metadata": {
        "id": "OiV6t-qGHiDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train\n",
        "k = 5\n",
        "knn = KNeighborsRegressor(n_neighbors=k)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_knn = knn.predict(X_test_scaled)\n",
        "residuals_knn = y_test - y_pred_knn\n",
        "\n",
        "#  Metrics\n",
        "metrics_knn = {\n",
        "    \"MAE\": mean_absolute_error(y_test, y_pred_knn),\n",
        "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_knn)),\n",
        "    \"R²\": r2_score(y_test, y_pred_knn),\n",
        "    \"RSE\": np.sqrt(np.sum(residuals_knn ** 2) / (len(y_test) - 2)),\n",
        "    \"Mean Residual\": residuals_knn.mean()\n",
        "}\n",
        "\n",
        "#  Output\n",
        "print(\"\\nKNN Regression Evaluation:\")\n",
        "for metric, value in metrics_knn.items():\n",
        "    if metric == \"R²\":\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"{metric}: {value:.2f}\")\n",
        "\n",
        "bias_direction = \"Underpredicting\" if metrics_knn[\"Mean Residual\"] > 0 else \"Overpredicting\"\n",
        "print(f\"Mean Residual: {metrics_knn['Mean Residual']:.2f} — {bias_direction} on average\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MGFLX9VJFzsE",
        "outputId": "ef3de077-4f87-4664-ecfb-5577215299b8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KNN Regression Evaluation:\n",
            "MAE: 41413723.35\n",
            "RMSE: 73888717.60\n",
            "R²: 0.6070\n",
            "RSE: 73970861.83\n",
            "Mean Residual: 11513964.25\n",
            "Mean Residual: 11513964.25 — Underpredicting on average\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell evaluates a K-Nearest Neighbors (KNN) regression model on the movie revenue prediction task. First, it applies feature standardization using StandardScaler to ensure that all input variables contribute equally to distance calculations, which is critical for distance-based models like KNN. The scaler is fit on the training data and then used to transform both training and test feature sets.\n",
        "\n",
        "Next, a KNeighborsRegressor is initialized with k = 5 neighbors and trained on the scaled training data. Predictions are made on the standardized test set, and residuals are calculated by subtracting the predicted revenues from the actual values.\n",
        "\n",
        "Evaluation metrics are then computed to assess the model's performance. These include:\n",
        "\n",
        "Mean Absolute Error (MAE): the average magnitude of prediction errors,\n",
        "\n",
        "Root Mean Squared Error (RMSE): penalizes larger errors more heavily,\n",
        "\n",
        "R² Score: indicates the proportion of variance in revenue explained by the model,\n",
        "\n",
        "Residual Standard Error (RSE): a measure of prediction dispersion,\n",
        "\n",
        "Mean Residual: used to diagnose average prediction bias.\n",
        "\n",
        "The output includes a detailed printout of these metrics, and the code concludes by interpreting whether the model underpredicts or overpredicts revenue on average based on the sign of the mean residual. This evaluation helps validate both the accuracy and bias tendency of the KNN model."
      ],
      "metadata": {
        "id": "Gb1yaNtGPIXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regression"
      ],
      "metadata": {
        "id": "z7YYiHYCHpAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Train full\n",
        "rf_full = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=25,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=1,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_full.fit(X_train, y_train)\n",
        "\n",
        "# top 20\n",
        "importances = pd.Series(rf_full.feature_importances_, index=X_train.columns)\n",
        "top_features = importances.nlargest(20).index.tolist()\n",
        "\n",
        "# Restrict datasets\n",
        "X_train_top = X_train[top_features]\n",
        "X_test_top = X_test[top_features]\n",
        "\n",
        "#Retrain model\n",
        "rf_top = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=25,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=1,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_top.fit(X_train_top, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = rf_top.predict(X_test_top)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "metrics_rf = {\n",
        "    \"MAE\": mean_absolute_error(y_test, y_pred),\n",
        "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "    \"R²\": r2_score(y_test, y_pred),\n",
        "    \"RSE\": np.sqrt(np.sum(residuals ** 2) / (len(y_test) - 2)),\n",
        "    \"Mean Residual\": residuals.mean()\n",
        "}\n",
        "\n",
        "# Output report\n",
        "print(\"\\nRandom Forest Evaluation on Top 20 Features:\")\n",
        "for metric, value in metrics_rf.items():\n",
        "    if metric == \"R²\":\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"{metric}: {value:.2f}\")\n",
        "\n",
        "bias_note = \"Underpredicting\" if metrics_rf[\"Mean Residual\"] > 0 else \"Overpredicting\"\n",
        "print(f\"Mean Residual: {metrics_rf['Mean Residual']:.2f} — {bias_note} on average\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qX9qR3GHGCt0",
        "outputId": "b2a579c3-18dd-4869-8c0e-bf984e147479"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Evaluation on Top 20 Features:\n",
            "MAE: 30755676.05\n",
            "RMSE: 57862392.42\n",
            "R²: 0.7590\n",
            "RSE: 57926719.72\n",
            "Mean Residual: 2402329.43\n",
            "Mean Residual: 2402329.43 — Underpredicting on average\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell leverages a Random Forest regression model to predict movie revenues and pinpoints the significant features influencing the model’s predictions. We start by training a comprehensive RandomForestRegressor with 200 trees, each having a maximum depth of 25. The parameters such as min_samples_split=5, min_samples_leaf=1, and max_features='sqrt' are chosen to maintain a good balance between overfitting and generalization.\n",
        "\n",
        "Once the model is trained using all the features from the training dataset, we extract and sort feature importances, highlighting the top 20 that impact the model’s decisions the most. These top features are believed to best predict revenue, so we revise our data to only include them, creating a robust feature set.\n",
        "\n",
        "We then train a new Random Forest model with just these top 20 features and make predictions on the test data. The performance is evaluated using Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), R² score, Residual Standard Error (RSE), and Mean Residual.\n",
        "\n",
        "Once the metrics are printed, we check the sign of the mean residual for prediction bias—whether it tends to overestimate or underestimate on average. Overall, this process refines our Random Forest model’s performance and interpretability.\n"
      ],
      "metadata": {
        "id": "MLACjsVdPYDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Cross-Validation"
      ],
      "metadata": {
        "id": "5hvZjn4NHtD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#top 20 features\n",
        "importances = pd.Series(model_top_20.feature_importances_, index=X_train_top.columns)\n",
        "top_20 = importances.nlargest(20).index.tolist()\n",
        "\n",
        "# Set up cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
        "cv_results = {}\n",
        "\n",
        "print(\"\\nCross-validation across models (5-Fold):\")\n",
        "\n",
        "\n",
        "def run_cv(model_name, model, X_input):\n",
        "    results = {}\n",
        "    for metric in scoring:\n",
        "        scores = cross_val_score(model, X_input, y, cv=kf, scoring=metric)\n",
        "        if metric == 'neg_mean_squared_error':\n",
        "            results['rmse'] = np.sqrt(-scores)\n",
        "            results['avg_rmse'] = np.sqrt(-scores.mean())\n",
        "        elif metric == 'neg_mean_absolute_error':\n",
        "            results['mae'] = -scores\n",
        "            results['avg_mae'] = -scores.mean()\n",
        "        else:\n",
        "            results['r2'] = scores\n",
        "            results['avg_r2'] = scores.mean()\n",
        "    cv_results[model_name] = results\n",
        "\n",
        "# Linear\n",
        "run_cv(\"Linear Regression\", LinearRegression(), X)\n",
        "\n",
        "# KNN\n",
        "knn_pipe = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=5))\n",
        "run_cv(\"KNN\", knn_pipe, X)\n",
        "\n",
        "# Random Forest\n",
        "X_top = X[top_20]\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200, max_depth=25, min_samples_split=5,\n",
        "    min_samples_leaf=1, max_features='sqrt', random_state=42, n_jobs=-1\n",
        ")\n",
        "run_cv(\"Random Forest\", rf_model, X_top)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(name, model, X_tr, X_te, y_tr, y_te, num_features):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_te)\n",
        "    residuals = y_te - y_pred\n",
        "    return {\n",
        "        'name': name,\n",
        "        'mae': mean_absolute_error(y_te, y_pred),\n",
        "        'rmse': np.sqrt(mean_squared_error(y_te, y_pred)),\n",
        "        'r2': r2_score(y_te, y_pred),\n",
        "        'rse': np.sqrt(np.sum(residuals ** 2) / (len(y_te) - num_features - 1)),\n",
        "        'mean_residual': residuals.mean(),\n",
        "        'bias': \"Underpredicting\" if residuals.mean() > 0 else \"Overpredicting\"\n",
        "    }\n",
        "\n",
        "test_results = []\n",
        "\n",
        "# Linear Regression\n",
        "test_results.append(\n",
        "    evaluate_model(\"Linear Regression (all features)\", LinearRegression(), X_train, X_test, y_train, y_test, X_train.shape[1])\n",
        ")\n",
        "\n",
        "# KNN\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "test_results.append(\n",
        "    evaluate_model(\"KNN Regression (all features)\", KNeighborsRegressor(n_neighbors=5), X_train_scaled, X_test_scaled, y_train, y_test, X_train.shape[1])\n",
        ")\n",
        "\n",
        "# Random Forest\n",
        "test_results.append(\n",
        "    evaluate_model(\"Random Forest (top 20 features)\", rf_model, X_train[top_20], X_test[top_20], y_train, y_test, len(top_20))\n",
        ")\n",
        "\n",
        "# Test Set Evaluations\n",
        "for res in test_results:\n",
        "    print(f\"\\n{res['name']} Evaluation:\")\n",
        "    print(f\"MAE: {res['mae']:.2f}\")\n",
        "    print(f\"RMSE: {res['rmse']:.2f}\")\n",
        "    print(f\"R²: {res['r2']:.4f}\")\n",
        "    print(f\"RSE: {res['rse']:.2f}\")\n",
        "    print(f\"Mean Residual: {res['mean_residual']:.2f} — {res['bias']} on average\")\n",
        "\n",
        "# Compare\n",
        "print(\"\\nCross-Validation vs. Test R² Comparison:\")\n",
        "for model_name, res in zip(cv_results.keys(), test_results):\n",
        "    cv_r2 = cv_results[model_name]['avg_r2']\n",
        "    test_r2 = res['r2']\n",
        "    print(f\"{model_name} - CV R²: {cv_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
        "    if cv_r2 > test_r2:\n",
        "        print(\"  → Test performance was worse than CV estimate\")\n",
        "    elif cv_r2 < test_r2:\n",
        "        print(\"  → Test performance was better than CV estimate\")\n",
        "    else:\n",
        "        print(\"  → Test performance matched CV estimate\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xa8MV26yGXlK",
        "outputId": "3143440d-d99c-4284-cb86-bc295e784932"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-validation across models (5-Fold):\n",
            "\n",
            "Linear Regression (all features) Evaluation:\n",
            "MAE: 36179445.72\n",
            "RMSE: 56690486.65\n",
            "R²: 0.7686\n",
            "RSE: 60050248.37\n",
            "Mean Residual: 2139281.73 — Underpredicting on average\n",
            "\n",
            "KNN Regression (all features) Evaluation:\n",
            "MAE: 41413723.35\n",
            "RMSE: 73888717.60\n",
            "R²: 0.6070\n",
            "RSE: 78267732.48\n",
            "Mean Residual: 11513964.25 — Underpredicting on average\n",
            "\n",
            "Random Forest (top 20 features) Evaluation:\n",
            "MAE: 31242194.72\n",
            "RMSE: 58414129.46\n",
            "R²: 0.7544\n",
            "RSE: 59107006.96\n",
            "Mean Residual: 2507882.33 — Underpredicting on average\n",
            "\n",
            "Cross-Validation vs. Test R² Comparison:\n",
            "Linear Regression - CV R²: 0.7482, Test R²: 0.7686\n",
            "  → Test performance was better than CV estimate\n",
            "KNN - CV R²: 0.6102, Test R²: 0.6070\n",
            "  → Test performance was worse than CV estimate\n",
            "Random Forest - CV R²: 0.7542, Test R²: 0.7544\n",
            "  → Test performance was better than CV estimate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code cell is used for k-Cross Validation for standard Linear Regression, KNN, Random Forest models. We have first extracted out the top 20 RF 100-Tree from a pre-trained model to optimize the RF model as the tuning process is very time-consuming. We use KFold and CV to split our data into 5 sets for creating different combinations and use the run_cv() function to calculate the standard metrics. We calculate the RSE and Mean Residual on a separate test set using the evaluate_model() function to check if our model systematically over or underpredicts the target variable. Lastly, we check if the model might be overfitting by comparing CV R^2 with test R^2.\n"
      ],
      "metadata": {
        "id": "oLPO2UQ9PopH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, we used a machine learning pipeline to predict movie revenues using features from the TMDB dataset. After training models, cross-validation, and test set evaluation, we evaluated the performance of Linear Regression, K-Nearest Neighbors, and Random Forest, with the Random Forest model consistently delivering strong predictive performance with minimal bias.\n"
      ],
      "metadata": {
        "id": "HMKuilLTPvDR"
      }
    }
  ]
}